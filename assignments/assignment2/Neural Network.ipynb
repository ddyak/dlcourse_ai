{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_out\n",
      "Gradient check passed!\n",
      "Checking gradient for W_in\n",
      "Gradient check passed!\n",
      "Checking gradient for B_out\n",
      "Gradient check passed!\n",
      "Checking gradient for B_in\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_out\n",
      "Gradient check passed!\n",
      "Checking gradient for W_in\n",
      "Gradient check passed!\n",
      "Checking gradient for B_out\n",
      "Gradient check passed!\n",
      "Checking gradient for B_in\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?\n",
    "\n",
    "**Ответ:** В среднем 0.1, поскольку сеть нетренирована. Флуктуации обеспечены рандомным распределением весов сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.256525, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234411, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218805, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299442, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250353, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204378, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.344327, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242054, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280916, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261553, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259453, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301086, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.339098, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268823, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.367442, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226122, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320075, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.310768, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297086, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290384, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** Уменьшил коэффициент регуляризации с 1e1 до 1e-1, поскольку функция потерь не уменьшалась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6f168345c0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.275985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.347515, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264348, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.353994, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.378711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264767, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274562, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308261, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264990, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276510, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314133, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278750, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315651, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351801, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319693, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.295926, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.345443, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310013, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.326544, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.255641, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199259, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.164561, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.025661, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883798, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.263931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.662918, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.245522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943906, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.663953, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.042200, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.418303, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.519709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.823944, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.585656, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937038, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908215, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.233499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.095108, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.718242, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.162756, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.015933, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.363952, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.842670, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.657567, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.388463, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.911120, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.693765, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.010436, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.115900, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613706, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.738574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.885192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.474042, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.119274, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.672047, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.767860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.478802, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.926619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.337383, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.683186, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.660081, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.401881, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.635264, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.635617, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.622938, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.854111, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.556636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634732, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.076198, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.007559, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.531114, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.041336, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.022564, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369538, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.379903, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.986917, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318972, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.283966, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936269, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.196061, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.739352, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.201189, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.582981, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.742143, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.293135, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.748190, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.976545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.357876, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.992895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602046, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602167, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.173057, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.312798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.564551, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.961713, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.274091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.304703, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.958926, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.377168, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.657193, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.389767, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.576803, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.556738, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.175409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322616, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.251510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.060407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.661861, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227308, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.597969, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.887250, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.338688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.842966, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.160604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.347215, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223119, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.436648, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.535320, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249121, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.248964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.549803, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.259687, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097239, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.324286, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.315431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.420746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443017, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.301618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.533658, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.607993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.239065, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.649177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.602848, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.363682, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.197888, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.126413, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.008120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.643235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.592807, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412599, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.212850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196541, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.280346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.403204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229377, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.102808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.445285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219193, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449330, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.304464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.494726, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.361608, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.424061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!\n",
    "\n",
    "**Комментарий**: Перед тем как устроить перебор по всей сетке параметров, подберем на глаз: поставим Momentum, увеличим число нейронов в скрытом слое, поставим не такую большую регуляризацию. В случае успеха не придется делать перебор.\n",
    "\n",
    "UPD: Сработало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.308723, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.304107, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.261888, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.197640, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.000701, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.682325, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.603348, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.851231, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.122996, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 1.678297, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.986914, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.856270, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.380942, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.262060, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.821596, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.201604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.393748, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.376190, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.130528, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.019262, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 300, reg = 1e-5)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1, num_epochs=20, batch_size=10)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.254306, Train accuracy: 0.331222, val accuracy: 0.328000\n",
      "Loss: 2.126411, Train accuracy: 0.390778, val accuracy: 0.384000\n",
      "Loss: 1.599023, Train accuracy: 0.571889, val accuracy: 0.563000\n",
      "Loss: 1.760083, Train accuracy: 0.574556, val accuracy: 0.556000\n",
      "Loss: 1.589157, Train accuracy: 0.608889, val accuracy: 0.595000\n",
      "Loss: 1.722784, Train accuracy: 0.645889, val accuracy: 0.620000\n",
      "Loss: 1.604754, Train accuracy: 0.604667, val accuracy: 0.580000\n",
      "Loss: 1.350564, Train accuracy: 0.620778, val accuracy: 0.587000\n",
      "Loss: 1.217317, Train accuracy: 0.656000, val accuracy: 0.634000\n",
      "Loss: 1.455710, Train accuracy: 0.629111, val accuracy: 0.602000\n",
      "Loss: 1.511602, Train accuracy: 0.628111, val accuracy: 0.609000\n",
      "Loss: 1.824530, Train accuracy: 0.670667, val accuracy: 0.649000\n",
      "Loss: 1.476099, Train accuracy: 0.647778, val accuracy: 0.621000\n",
      "Loss: 1.855392, Train accuracy: 0.666778, val accuracy: 0.642000\n",
      "Loss: 1.348010, Train accuracy: 0.648111, val accuracy: 0.643000\n",
      "Loss: 1.547200, Train accuracy: 0.643556, val accuracy: 0.604000\n",
      "Loss: 2.282394, Train accuracy: 0.196778, val accuracy: 0.206000\n",
      "Loss: 1.796187, Train accuracy: 0.413222, val accuracy: 0.413000\n",
      "Loss: 1.388561, Train accuracy: 0.522556, val accuracy: 0.528000\n",
      "Loss: 1.355581, Train accuracy: 0.551667, val accuracy: 0.533000\n",
      "Loss: 1.347657, Train accuracy: 0.626222, val accuracy: 0.621000\n",
      "Loss: 1.256202, Train accuracy: 0.649667, val accuracy: 0.637000\n",
      "Loss: 1.573478, Train accuracy: 0.686333, val accuracy: 0.654000\n",
      "Loss: 1.020023, Train accuracy: 0.677111, val accuracy: 0.640000\n",
      "Loss: 1.420729, Train accuracy: 0.693000, val accuracy: 0.661000\n",
      "Loss: 1.247349, Train accuracy: 0.706778, val accuracy: 0.642000\n",
      "Loss: 1.085667, Train accuracy: 0.697889, val accuracy: 0.649000\n",
      "Loss: 1.111005, Train accuracy: 0.681889, val accuracy: 0.650000\n",
      "Loss: 1.375995, Train accuracy: 0.692889, val accuracy: 0.654000\n",
      "Loss: 1.096636, Train accuracy: 0.713333, val accuracy: 0.657000\n",
      "Loss: 1.338693, Train accuracy: 0.724111, val accuracy: 0.681000\n",
      "Loss: 1.507795, Train accuracy: 0.712444, val accuracy: 0.662000\n",
      "Loss: 1.918294, Train accuracy: 0.344000, val accuracy: 0.340000\n",
      "Loss: 1.534832, Train accuracy: 0.505444, val accuracy: 0.503000\n",
      "Loss: 1.196199, Train accuracy: 0.608778, val accuracy: 0.610000\n",
      "Loss: 1.659714, Train accuracy: 0.607111, val accuracy: 0.565000\n",
      "Loss: 1.953897, Train accuracy: 0.579778, val accuracy: 0.570000\n",
      "Loss: 2.243311, Train accuracy: 0.621667, val accuracy: 0.592000\n",
      "Loss: 1.441544, Train accuracy: 0.632889, val accuracy: 0.592000\n",
      "Loss: 1.970416, Train accuracy: 0.645222, val accuracy: 0.616000\n",
      "Loss: 1.229949, Train accuracy: 0.634556, val accuracy: 0.601000\n",
      "Loss: 1.678381, Train accuracy: 0.612000, val accuracy: 0.598000\n",
      "Loss: 2.274946, Train accuracy: 0.560778, val accuracy: 0.547000\n",
      "Loss: 1.603266, Train accuracy: 0.663556, val accuracy: 0.644000\n",
      "Loss: 1.637930, Train accuracy: 0.637778, val accuracy: 0.603000\n",
      "Loss: 1.469989, Train accuracy: 0.677222, val accuracy: 0.637000\n",
      "Loss: 1.664509, Train accuracy: 0.637111, val accuracy: 0.616000\n",
      "Loss: 1.242116, Train accuracy: 0.663444, val accuracy: 0.633000\n",
      "Loss: 2.297040, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.659186, Train accuracy: 0.419333, val accuracy: 0.431000\n",
      "Loss: 1.469761, Train accuracy: 0.582556, val accuracy: 0.561000\n",
      "Loss: 1.448300, Train accuracy: 0.660111, val accuracy: 0.650000\n",
      "Loss: 1.865019, Train accuracy: 0.647889, val accuracy: 0.624000\n",
      "Loss: 1.353616, Train accuracy: 0.638333, val accuracy: 0.608000\n",
      "Loss: 1.059922, Train accuracy: 0.689111, val accuracy: 0.655000\n",
      "Loss: 0.953610, Train accuracy: 0.721556, val accuracy: 0.684000\n",
      "Loss: 0.959192, Train accuracy: 0.711667, val accuracy: 0.674000\n",
      "Loss: 1.066867, Train accuracy: 0.664667, val accuracy: 0.628000\n",
      "Loss: 1.308567, Train accuracy: 0.721444, val accuracy: 0.666000\n",
      "Loss: 1.446622, Train accuracy: 0.746889, val accuracy: 0.682000\n",
      "Loss: 1.211784, Train accuracy: 0.720000, val accuracy: 0.664000\n",
      "Loss: 1.501833, Train accuracy: 0.708889, val accuracy: 0.642000\n",
      "Loss: 1.230393, Train accuracy: 0.737889, val accuracy: 0.662000\n",
      "Loss: 1.753488, Train accuracy: 0.737556, val accuracy: 0.658000\n",
      "Loss: 1.822053, Train accuracy: 0.399667, val accuracy: 0.388000\n",
      "Loss: 2.141065, Train accuracy: 0.516778, val accuracy: 0.511000\n",
      "Loss: 1.802007, Train accuracy: 0.547000, val accuracy: 0.521000\n",
      "Loss: 1.635750, Train accuracy: 0.593222, val accuracy: 0.559000\n",
      "Loss: 1.891536, Train accuracy: 0.595667, val accuracy: 0.597000\n",
      "Loss: 2.245850, Train accuracy: 0.662222, val accuracy: 0.619000\n",
      "Loss: 1.748559, Train accuracy: 0.619111, val accuracy: 0.589000\n",
      "Loss: 1.778481, Train accuracy: 0.619444, val accuracy: 0.576000\n",
      "Loss: 1.859497, Train accuracy: 0.623000, val accuracy: 0.588000\n",
      "Loss: 1.766714, Train accuracy: 0.628667, val accuracy: 0.576000\n",
      "Loss: 1.576040, Train accuracy: 0.582000, val accuracy: 0.546000\n",
      "Loss: 1.551864, Train accuracy: 0.605111, val accuracy: 0.584000\n",
      "Loss: 2.192881, Train accuracy: 0.647889, val accuracy: 0.610000\n",
      "Loss: 1.362135, Train accuracy: 0.571778, val accuracy: 0.549000\n",
      "Loss: 1.821858, Train accuracy: 0.581444, val accuracy: 0.547000\n",
      "Loss: 2.068293, Train accuracy: 0.640222, val accuracy: 0.605000\n",
      "Loss: 1.979435, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.705427, Train accuracy: 0.445667, val accuracy: 0.452000\n",
      "Loss: 1.406649, Train accuracy: 0.543222, val accuracy: 0.516000\n",
      "Loss: 1.557181, Train accuracy: 0.650000, val accuracy: 0.638000\n",
      "Loss: 1.223572, Train accuracy: 0.656222, val accuracy: 0.620000\n",
      "Loss: 1.295975, Train accuracy: 0.662667, val accuracy: 0.657000\n",
      "Loss: 1.550672, Train accuracy: 0.697444, val accuracy: 0.659000\n",
      "Loss: 1.424320, Train accuracy: 0.691667, val accuracy: 0.666000\n",
      "Loss: 0.908337, Train accuracy: 0.683889, val accuracy: 0.639000\n",
      "Loss: 1.226932, Train accuracy: 0.682222, val accuracy: 0.634000\n",
      "Loss: 1.137795, Train accuracy: 0.692667, val accuracy: 0.628000\n",
      "Loss: 1.241496, Train accuracy: 0.744889, val accuracy: 0.703000\n",
      "Loss: 1.103151, Train accuracy: 0.789222, val accuracy: 0.719000\n",
      "Loss: 1.178115, Train accuracy: 0.735889, val accuracy: 0.658000\n",
      "Loss: 1.378131, Train accuracy: 0.755667, val accuracy: 0.686000\n",
      "Loss: 1.015791, Train accuracy: 0.740889, val accuracy: 0.687000\n",
      "Loss: 1.685640, Train accuracy: 0.353556, val accuracy: 0.365000\n",
      "Loss: 1.426788, Train accuracy: 0.552778, val accuracy: 0.560000\n",
      "Loss: 1.481496, Train accuracy: 0.618222, val accuracy: 0.583000\n",
      "Loss: 1.322246, Train accuracy: 0.600444, val accuracy: 0.590000\n",
      "Loss: 1.306398, Train accuracy: 0.620778, val accuracy: 0.607000\n",
      "Loss: 1.144718, Train accuracy: 0.666889, val accuracy: 0.633000\n",
      "Loss: 1.331177, Train accuracy: 0.691111, val accuracy: 0.641000\n",
      "Loss: 1.210353, Train accuracy: 0.691778, val accuracy: 0.617000\n",
      "Loss: 1.258379, Train accuracy: 0.716778, val accuracy: 0.661000\n",
      "Loss: 1.329283, Train accuracy: 0.732556, val accuracy: 0.669000\n",
      "Loss: 1.127117, Train accuracy: 0.729667, val accuracy: 0.665000\n",
      "Loss: 1.574156, Train accuracy: 0.755667, val accuracy: 0.674000\n",
      "Loss: 0.998659, Train accuracy: 0.710222, val accuracy: 0.640000\n",
      "Loss: 1.102199, Train accuracy: 0.761000, val accuracy: 0.677000\n",
      "Loss: 0.870651, Train accuracy: 0.736556, val accuracy: 0.668000\n",
      "Loss: 0.574188, Train accuracy: 0.774333, val accuracy: 0.691000\n",
      "Loss: 2.046903, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.028230, Train accuracy: 0.381556, val accuracy: 0.383000\n",
      "Loss: 1.630101, Train accuracy: 0.521778, val accuracy: 0.513000\n",
      "Loss: 1.123517, Train accuracy: 0.600889, val accuracy: 0.595000\n",
      "Loss: 1.171586, Train accuracy: 0.668667, val accuracy: 0.646000\n",
      "Loss: 1.141698, Train accuracy: 0.691444, val accuracy: 0.646000\n",
      "Loss: 0.982875, Train accuracy: 0.705778, val accuracy: 0.660000\n",
      "Loss: 1.603487, Train accuracy: 0.715444, val accuracy: 0.668000\n",
      "Loss: 0.805178, Train accuracy: 0.755444, val accuracy: 0.683000\n",
      "Loss: 1.375112, Train accuracy: 0.782778, val accuracy: 0.716000\n",
      "Loss: 0.473615, Train accuracy: 0.786222, val accuracy: 0.706000\n",
      "Loss: 0.981651, Train accuracy: 0.764111, val accuracy: 0.695000\n",
      "Loss: 0.616460, Train accuracy: 0.790889, val accuracy: 0.705000\n",
      "Loss: 1.130234, Train accuracy: 0.784778, val accuracy: 0.707000\n",
      "Loss: 0.385131, Train accuracy: 0.764444, val accuracy: 0.685000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.658248, Train accuracy: 0.753778, val accuracy: 0.666000\n",
      "Loss: 1.927966, Train accuracy: 0.348222, val accuracy: 0.354000\n",
      "Loss: 1.867780, Train accuracy: 0.556667, val accuracy: 0.552000\n",
      "Loss: 0.892738, Train accuracy: 0.627889, val accuracy: 0.608000\n",
      "Loss: 1.123378, Train accuracy: 0.620333, val accuracy: 0.592000\n",
      "Loss: 0.961163, Train accuracy: 0.659333, val accuracy: 0.623000\n",
      "Loss: 1.145410, Train accuracy: 0.690333, val accuracy: 0.642000\n",
      "Loss: 1.186451, Train accuracy: 0.726667, val accuracy: 0.663000\n",
      "Loss: 1.162200, Train accuracy: 0.689000, val accuracy: 0.639000\n",
      "Loss: 0.867996, Train accuracy: 0.712444, val accuracy: 0.645000\n",
      "Loss: 1.174919, Train accuracy: 0.744222, val accuracy: 0.678000\n",
      "Loss: 0.612320, Train accuracy: 0.730667, val accuracy: 0.654000\n",
      "Loss: 0.708881, Train accuracy: 0.766444, val accuracy: 0.694000\n",
      "Loss: 0.933329, Train accuracy: 0.756667, val accuracy: 0.688000\n",
      "Loss: 1.129005, Train accuracy: 0.761778, val accuracy: 0.671000\n",
      "Loss: 1.248485, Train accuracy: 0.766778, val accuracy: 0.680000\n",
      "Loss: 1.059362, Train accuracy: 0.753444, val accuracy: 0.643000\n",
      "Loss: 2.202061, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.831331, Train accuracy: 0.419222, val accuracy: 0.427000\n",
      "Loss: 1.282814, Train accuracy: 0.554222, val accuracy: 0.557000\n",
      "Loss: 1.190227, Train accuracy: 0.597222, val accuracy: 0.588000\n",
      "Loss: 0.859605, Train accuracy: 0.667000, val accuracy: 0.654000\n",
      "Loss: 0.891884, Train accuracy: 0.682778, val accuracy: 0.641000\n",
      "Loss: 1.460778, Train accuracy: 0.667556, val accuracy: 0.634000\n",
      "Loss: 0.618438, Train accuracy: 0.725222, val accuracy: 0.661000\n",
      "Loss: 0.703884, Train accuracy: 0.752333, val accuracy: 0.667000\n",
      "Loss: 0.630782, Train accuracy: 0.751000, val accuracy: 0.673000\n",
      "Loss: 0.571686, Train accuracy: 0.767000, val accuracy: 0.677000\n",
      "Loss: 0.858808, Train accuracy: 0.774667, val accuracy: 0.685000\n",
      "Loss: 0.825459, Train accuracy: 0.786667, val accuracy: 0.707000\n",
      "Loss: 0.929023, Train accuracy: 0.794556, val accuracy: 0.690000\n",
      "Loss: 0.727656, Train accuracy: 0.809111, val accuracy: 0.709000\n",
      "Loss: 1.088138, Train accuracy: 0.822000, val accuracy: 0.721000\n",
      "Loss: 1.794897, Train accuracy: 0.342556, val accuracy: 0.347000\n",
      "Loss: 1.283811, Train accuracy: 0.564889, val accuracy: 0.545000\n",
      "Loss: 1.479591, Train accuracy: 0.605778, val accuracy: 0.595000\n",
      "Loss: 1.372194, Train accuracy: 0.622556, val accuracy: 0.600000\n",
      "Loss: 1.422777, Train accuracy: 0.639556, val accuracy: 0.588000\n",
      "Loss: 1.016250, Train accuracy: 0.697333, val accuracy: 0.659000\n",
      "Loss: 1.225558, Train accuracy: 0.683889, val accuracy: 0.636000\n",
      "Loss: 1.400798, Train accuracy: 0.636222, val accuracy: 0.592000\n",
      "Loss: 1.520683, Train accuracy: 0.708333, val accuracy: 0.644000\n",
      "Loss: 0.763430, Train accuracy: 0.746000, val accuracy: 0.668000\n",
      "Loss: 1.160936, Train accuracy: 0.762222, val accuracy: 0.671000\n",
      "Loss: 0.821599, Train accuracy: 0.737222, val accuracy: 0.674000\n",
      "Loss: 2.392201, Train accuracy: 0.751444, val accuracy: 0.649000\n",
      "Loss: 0.745817, Train accuracy: 0.772000, val accuracy: 0.683000\n",
      "Loss: 0.581247, Train accuracy: 0.767333, val accuracy: 0.687000\n",
      "Loss: 0.994627, Train accuracy: 0.785778, val accuracy: 0.694000\n",
      "Loss: 2.333988, Train accuracy: 0.240000, val accuracy: 0.243000\n",
      "Loss: 1.595211, Train accuracy: 0.430667, val accuracy: 0.420000\n",
      "Loss: 1.223798, Train accuracy: 0.576222, val accuracy: 0.560000\n",
      "Loss: 1.091777, Train accuracy: 0.638889, val accuracy: 0.620000\n",
      "Loss: 0.910332, Train accuracy: 0.670333, val accuracy: 0.648000\n",
      "Loss: 1.020046, Train accuracy: 0.707333, val accuracy: 0.662000\n",
      "Loss: 1.207852, Train accuracy: 0.686778, val accuracy: 0.634000\n",
      "Loss: 0.923376, Train accuracy: 0.753889, val accuracy: 0.697000\n",
      "Loss: 0.816725, Train accuracy: 0.742444, val accuracy: 0.673000\n",
      "Loss: 0.585534, Train accuracy: 0.755556, val accuracy: 0.666000\n",
      "Loss: 1.075660, Train accuracy: 0.800111, val accuracy: 0.717000\n",
      "Loss: 0.598124, Train accuracy: 0.792667, val accuracy: 0.700000\n",
      "Loss: 0.885626, Train accuracy: 0.817000, val accuracy: 0.725000\n",
      "Loss: 1.573319, Train accuracy: 0.805111, val accuracy: 0.714000\n",
      "Loss: 0.677455, Train accuracy: 0.808556, val accuracy: 0.718000\n",
      "Loss: 0.361824, Train accuracy: 0.831667, val accuracy: 0.710000\n",
      "Loss: 2.251618, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207555, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179553, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.195512, Train accuracy: 0.243111, val accuracy: 0.240000\n",
      "Loss: 1.904117, Train accuracy: 0.276556, val accuracy: 0.286000\n",
      "Loss: 1.662915, Train accuracy: 0.381889, val accuracy: 0.381000\n",
      "Loss: 1.470661, Train accuracy: 0.450333, val accuracy: 0.445000\n",
      "Loss: 1.745269, Train accuracy: 0.501333, val accuracy: 0.491000\n",
      "Loss: 1.538423, Train accuracy: 0.554556, val accuracy: 0.557000\n",
      "Loss: 1.506245, Train accuracy: 0.602889, val accuracy: 0.589000\n",
      "Loss: 1.356762, Train accuracy: 0.616556, val accuracy: 0.613000\n",
      "Loss: 1.480065, Train accuracy: 0.646000, val accuracy: 0.627000\n",
      "Loss: 1.315859, Train accuracy: 0.657556, val accuracy: 0.640000\n",
      "Loss: 1.222084, Train accuracy: 0.658889, val accuracy: 0.650000\n",
      "Loss: 1.052820, Train accuracy: 0.703333, val accuracy: 0.687000\n",
      "Loss: 1.151130, Train accuracy: 0.687556, val accuracy: 0.652000\n",
      "Loss: 2.257615, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237467, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235049, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259883, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214085, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.426179, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145073, Train accuracy: 0.212778, val accuracy: 0.218000\n",
      "Loss: 2.145946, Train accuracy: 0.253667, val accuracy: 0.252000\n",
      "Loss: 2.246884, Train accuracy: 0.275111, val accuracy: 0.278000\n",
      "Loss: 1.999682, Train accuracy: 0.292222, val accuracy: 0.294000\n",
      "Loss: 1.685464, Train accuracy: 0.337889, val accuracy: 0.340000\n",
      "Loss: 1.898616, Train accuracy: 0.391222, val accuracy: 0.379000\n",
      "Loss: 1.580447, Train accuracy: 0.422000, val accuracy: 0.416000\n",
      "Loss: 1.479108, Train accuracy: 0.455778, val accuracy: 0.438000\n",
      "Loss: 1.758589, Train accuracy: 0.493667, val accuracy: 0.491000\n",
      "Loss: 1.617894, Train accuracy: 0.516333, val accuracy: 0.503000\n",
      "Loss: 2.203022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204456, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.178056, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.975172, Train accuracy: 0.259667, val accuracy: 0.260000\n",
      "Loss: 1.932667, Train accuracy: 0.293222, val accuracy: 0.295000\n",
      "Loss: 1.794984, Train accuracy: 0.394222, val accuracy: 0.387000\n",
      "Loss: 1.719769, Train accuracy: 0.437889, val accuracy: 0.431000\n",
      "Loss: 1.514210, Train accuracy: 0.525444, val accuracy: 0.522000\n",
      "Loss: 1.625731, Train accuracy: 0.586556, val accuracy: 0.575000\n",
      "Loss: 1.234279, Train accuracy: 0.620333, val accuracy: 0.598000\n",
      "Loss: 1.249405, Train accuracy: 0.632000, val accuracy: 0.618000\n",
      "Loss: 1.219928, Train accuracy: 0.654000, val accuracy: 0.637000\n",
      "Loss: 1.467255, Train accuracy: 0.682444, val accuracy: 0.671000\n",
      "Loss: 1.126711, Train accuracy: 0.704000, val accuracy: 0.683000\n",
      "Loss: 1.090782, Train accuracy: 0.708000, val accuracy: 0.685000\n",
      "Loss: 1.166858, Train accuracy: 0.719667, val accuracy: 0.692000\n",
      "Loss: 2.223000, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201388, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.171729, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259411, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.310657, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180637, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153680, Train accuracy: 0.229222, val accuracy: 0.237000\n",
      "Loss: 2.023013, Train accuracy: 0.268556, val accuracy: 0.267000\n",
      "Loss: 1.848579, Train accuracy: 0.279556, val accuracy: 0.280000\n",
      "Loss: 2.077591, Train accuracy: 0.304111, val accuracy: 0.307000\n",
      "Loss: 1.707497, Train accuracy: 0.361000, val accuracy: 0.357000\n",
      "Loss: 1.665055, Train accuracy: 0.403333, val accuracy: 0.395000\n",
      "Loss: 1.729678, Train accuracy: 0.440667, val accuracy: 0.437000\n",
      "Loss: 1.604274, Train accuracy: 0.481111, val accuracy: 0.477000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.607930, Train accuracy: 0.510889, val accuracy: 0.513000\n",
      "Loss: 1.541639, Train accuracy: 0.546667, val accuracy: 0.547000\n",
      "Loss: 2.268879, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239465, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.194430, Train accuracy: 0.205667, val accuracy: 0.217000\n",
      "Loss: 2.073439, Train accuracy: 0.274667, val accuracy: 0.281000\n",
      "Loss: 1.839943, Train accuracy: 0.347444, val accuracy: 0.354000\n",
      "Loss: 1.824723, Train accuracy: 0.437444, val accuracy: 0.430000\n",
      "Loss: 1.509918, Train accuracy: 0.482778, val accuracy: 0.486000\n",
      "Loss: 1.198880, Train accuracy: 0.565778, val accuracy: 0.560000\n",
      "Loss: 1.530526, Train accuracy: 0.605444, val accuracy: 0.598000\n",
      "Loss: 1.390096, Train accuracy: 0.646667, val accuracy: 0.629000\n",
      "Loss: 1.169891, Train accuracy: 0.670778, val accuracy: 0.660000\n",
      "Loss: 1.320987, Train accuracy: 0.687333, val accuracy: 0.664000\n",
      "Loss: 1.163398, Train accuracy: 0.702333, val accuracy: 0.683000\n",
      "Loss: 1.033215, Train accuracy: 0.713000, val accuracy: 0.691000\n",
      "Loss: 1.354127, Train accuracy: 0.714667, val accuracy: 0.686000\n",
      "Loss: 0.961280, Train accuracy: 0.731111, val accuracy: 0.707000\n",
      "Loss: 2.269883, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.363315, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258907, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.110855, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225914, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187668, Train accuracy: 0.215000, val accuracy: 0.221000\n",
      "Loss: 2.047409, Train accuracy: 0.248667, val accuracy: 0.251000\n",
      "Loss: 1.982592, Train accuracy: 0.276333, val accuracy: 0.276000\n",
      "Loss: 2.038543, Train accuracy: 0.308778, val accuracy: 0.319000\n",
      "Loss: 2.103476, Train accuracy: 0.361333, val accuracy: 0.362000\n",
      "Loss: 1.734906, Train accuracy: 0.406000, val accuracy: 0.393000\n",
      "Loss: 1.857071, Train accuracy: 0.451556, val accuracy: 0.443000\n",
      "Loss: 1.632923, Train accuracy: 0.481444, val accuracy: 0.469000\n",
      "Loss: 1.589954, Train accuracy: 0.522222, val accuracy: 0.512000\n",
      "Loss: 1.498384, Train accuracy: 0.558556, val accuracy: 0.557000\n",
      "Loss: 1.304874, Train accuracy: 0.589667, val accuracy: 0.569000\n",
      "Loss: 2.289988, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238007, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292553, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.182730, Train accuracy: 0.253000, val accuracy: 0.257000\n",
      "Loss: 1.877553, Train accuracy: 0.294667, val accuracy: 0.299000\n",
      "Loss: 1.854529, Train accuracy: 0.395000, val accuracy: 0.384000\n",
      "Loss: 1.752844, Train accuracy: 0.463000, val accuracy: 0.459000\n",
      "Loss: 1.727977, Train accuracy: 0.529333, val accuracy: 0.521000\n",
      "Loss: 1.102909, Train accuracy: 0.583000, val accuracy: 0.570000\n",
      "Loss: 1.180660, Train accuracy: 0.617222, val accuracy: 0.601000\n",
      "Loss: 1.132314, Train accuracy: 0.641000, val accuracy: 0.634000\n",
      "Loss: 1.035496, Train accuracy: 0.653778, val accuracy: 0.641000\n",
      "Loss: 1.002736, Train accuracy: 0.686889, val accuracy: 0.664000\n",
      "Loss: 0.889522, Train accuracy: 0.699111, val accuracy: 0.677000\n",
      "Loss: 0.887631, Train accuracy: 0.705111, val accuracy: 0.680000\n",
      "Loss: 0.909662, Train accuracy: 0.722000, val accuracy: 0.696000\n",
      "Loss: 2.289843, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.185790, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223262, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.151479, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.135546, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202061, Train accuracy: 0.216556, val accuracy: 0.222000\n",
      "Loss: 2.148060, Train accuracy: 0.262556, val accuracy: 0.258000\n",
      "Loss: 1.954106, Train accuracy: 0.274889, val accuracy: 0.276000\n",
      "Loss: 2.055648, Train accuracy: 0.297444, val accuracy: 0.305000\n",
      "Loss: 1.790318, Train accuracy: 0.355889, val accuracy: 0.356000\n",
      "Loss: 1.715621, Train accuracy: 0.399444, val accuracy: 0.395000\n",
      "Loss: 1.725775, Train accuracy: 0.442444, val accuracy: 0.441000\n",
      "Loss: 1.753508, Train accuracy: 0.475000, val accuracy: 0.464000\n",
      "Loss: 1.603721, Train accuracy: 0.519111, val accuracy: 0.511000\n",
      "Loss: 1.271666, Train accuracy: 0.551111, val accuracy: 0.539000\n",
      "Loss: 2.239434, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.121695, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.058773, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.136085, Train accuracy: 0.266889, val accuracy: 0.264000\n",
      "Loss: 1.684052, Train accuracy: 0.330667, val accuracy: 0.338000\n",
      "Loss: 1.757726, Train accuracy: 0.414667, val accuracy: 0.417000\n",
      "Loss: 1.347075, Train accuracy: 0.494556, val accuracy: 0.502000\n",
      "Loss: 1.337596, Train accuracy: 0.557778, val accuracy: 0.563000\n",
      "Loss: 0.983048, Train accuracy: 0.599222, val accuracy: 0.589000\n",
      "Loss: 1.268152, Train accuracy: 0.631556, val accuracy: 0.628000\n",
      "Loss: 0.956209, Train accuracy: 0.657556, val accuracy: 0.656000\n",
      "Loss: 1.256869, Train accuracy: 0.689222, val accuracy: 0.674000\n",
      "Loss: 0.788791, Train accuracy: 0.696111, val accuracy: 0.666000\n",
      "Loss: 0.933741, Train accuracy: 0.716556, val accuracy: 0.675000\n",
      "Loss: 0.850515, Train accuracy: 0.716667, val accuracy: 0.698000\n",
      "Loss: 0.954659, Train accuracy: 0.743222, val accuracy: 0.704000\n",
      "Loss: 2.237853, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221059, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187397, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198040, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.127096, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142300, Train accuracy: 0.199000, val accuracy: 0.209000\n",
      "Loss: 2.040913, Train accuracy: 0.234667, val accuracy: 0.240000\n",
      "Loss: 2.126804, Train accuracy: 0.265444, val accuracy: 0.263000\n",
      "Loss: 1.994854, Train accuracy: 0.278667, val accuracy: 0.279000\n",
      "Loss: 2.022149, Train accuracy: 0.305667, val accuracy: 0.321000\n",
      "Loss: 1.676388, Train accuracy: 0.354222, val accuracy: 0.355000\n",
      "Loss: 1.762553, Train accuracy: 0.401889, val accuracy: 0.399000\n",
      "Loss: 1.338166, Train accuracy: 0.424222, val accuracy: 0.425000\n",
      "Loss: 1.471214, Train accuracy: 0.460778, val accuracy: 0.458000\n",
      "Loss: 1.720712, Train accuracy: 0.501222, val accuracy: 0.495000\n",
      "Loss: 1.510452, Train accuracy: 0.542111, val accuracy: 0.531000\n",
      "Loss: 2.220873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170003, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.102265, Train accuracy: 0.215222, val accuracy: 0.221000\n",
      "Loss: 2.003553, Train accuracy: 0.277889, val accuracy: 0.285000\n",
      "Loss: 1.866359, Train accuracy: 0.367778, val accuracy: 0.355000\n",
      "Loss: 1.666542, Train accuracy: 0.467889, val accuracy: 0.456000\n",
      "Loss: 1.511211, Train accuracy: 0.537000, val accuracy: 0.524000\n",
      "Loss: 1.214783, Train accuracy: 0.578444, val accuracy: 0.563000\n",
      "Loss: 1.450148, Train accuracy: 0.604000, val accuracy: 0.584000\n",
      "Loss: 1.027872, Train accuracy: 0.650000, val accuracy: 0.632000\n",
      "Loss: 1.107080, Train accuracy: 0.678556, val accuracy: 0.662000\n",
      "Loss: 1.266228, Train accuracy: 0.693889, val accuracy: 0.672000\n",
      "Loss: 0.809288, Train accuracy: 0.707556, val accuracy: 0.686000\n",
      "Loss: 0.725788, Train accuracy: 0.709556, val accuracy: 0.687000\n",
      "Loss: 1.220702, Train accuracy: 0.738111, val accuracy: 0.705000\n",
      "Loss: 1.169159, Train accuracy: 0.745778, val accuracy: 0.698000\n",
      "Loss: 2.269383, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.168217, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307187, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240944, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.148221, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.125828, Train accuracy: 0.210000, val accuracy: 0.219000\n",
      "Loss: 2.149337, Train accuracy: 0.264667, val accuracy: 0.260000\n",
      "Loss: 1.958116, Train accuracy: 0.280667, val accuracy: 0.279000\n",
      "Loss: 1.960467, Train accuracy: 0.310222, val accuracy: 0.311000\n",
      "Loss: 1.788591, Train accuracy: 0.376444, val accuracy: 0.382000\n",
      "Loss: 1.912907, Train accuracy: 0.414111, val accuracy: 0.401000\n",
      "Loss: 1.845096, Train accuracy: 0.451333, val accuracy: 0.444000\n",
      "Loss: 1.506228, Train accuracy: 0.501778, val accuracy: 0.487000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.306147, Train accuracy: 0.533111, val accuracy: 0.528000\n",
      "Loss: 1.324272, Train accuracy: 0.571667, val accuracy: 0.550000\n",
      "Loss: 1.270970, Train accuracy: 0.597889, val accuracy: 0.579000\n",
      "best validation accuracy achieved: 0.721000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "# Best parameters for now are (0.78, 50, 25, 200, 0.9, 0.8, 0.001, 0.1)\n",
    "# best_parameters = (val_history[len(val_history)-1], batch, epoch, laysize, decay, moment, reg, rate)\n",
    "\n",
    "learning_rates = [1e-1, 1e-2]\n",
    "reg_strength = [1e-3, 1e-5]\n",
    "hidden_layer_sizes = [64, 128, 256]\n",
    "batch_size = [64, 128]\n",
    "num_epochs = 16\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "for lr in learning_rates:\n",
    "    for rs in reg_strength:\n",
    "        for ls in hidden_layer_sizes:\n",
    "            for bs in batch_size:\n",
    "                model = TwoLayerNet(n_input=train_X.shape[1], n_output=10, hidden_layer_size=ls, reg=rs)\n",
    "                trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=lr, num_epochs=num_epochs, batch_size=bs)\n",
    "                temp_loss_history, temp_train_history, temp_val_history = trainer.fit()\n",
    "                \n",
    "                if temp_val_history[-1] > best_val_accuracy:\n",
    "                    best_classifier = model\n",
    "                    best_val_accuracy = temp_val_history[-1]\n",
    "                    loss_history = temp_loss_history.copy()\n",
    "                    train_history = temp_train_history.copy()\n",
    "                    val_history = temp_val_history.copy()\n",
    "    \n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6f1610efd0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.694000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
