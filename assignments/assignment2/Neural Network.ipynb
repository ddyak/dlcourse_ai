{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_out\n",
      "Gradient check passed!\n",
      "Checking gradient for W_in\n",
      "Gradient check passed!\n",
      "Checking gradient for B_out\n",
      "Gradient check passed!\n",
      "Checking gradient for B_in\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_out\n",
      "Gradient check passed!\n",
      "Checking gradient for W_in\n",
      "Gradient check passed!\n",
      "Checking gradient for B_out\n",
      "Gradient check passed!\n",
      "Checking gradient for B_in\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?\n",
    "\n",
    "**Ответ:** В среднем 0.1, поскольку сеть нетренирована. Флуктуации обеспечены рандомным распределением весов сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.217057, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.157437, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.115648, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287707, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.176635, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.070778, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.389343, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201810, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268138, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177243, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188959, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288565, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.324022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.376680, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181966, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288749, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281310, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235221, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb2a3afa518>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.250718, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.369508, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209910, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258537, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188416, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205064, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.126148, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.325751, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320998, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175592, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265976, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.363186, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.131519, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.410504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228590, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242233, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233189, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213630, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.321504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305573, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315005, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249502, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300977, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243300, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240870, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256889, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250501, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305861, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215956, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247150, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248955, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205055, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308770, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351618, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.318467, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.291136, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.341864, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.302463, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.319034, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.235521, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.170412, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.144598, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.000302, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.842682, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.238035, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.616099, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.203432, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.902569, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.637197, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.003430, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.394373, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.492224, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.807273, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022181, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.577554, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.866207, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908744, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.159965, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.083456, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.642604, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.125341, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.993812, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.343383, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.837536, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.609352, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.314199, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.798446, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.659346, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.933030, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.083985, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.491238, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.731915, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.788430, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 2.425725, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.017317, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.558682, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.728849, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.452117, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.861666, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.198709, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.657933, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.558153, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.384778, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 1.625072, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.549759, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.617123, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.739898, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.417619, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.533807, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 1.011228, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936917, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.408309, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.036403, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.865917, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.592674, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.323204, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.334323, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.938533, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.275339, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.253094, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.897369, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.138715, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.601602, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.564878, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.059963, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.502392, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.681630, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.228649, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.550753, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.786590, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.226258, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.957398, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.442177, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.435122, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.106624, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.231636, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.457298, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.921533, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.184508, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.222668, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.944016, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.295791, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.478291, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.294451, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.375229, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.415711, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.056241, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.258684, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.131832, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.053068, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.455916, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.092817, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412114, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.628100, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.204674, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.558378, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.095451, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.280285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.103288, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.309781, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.369390, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174232, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.173103, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.323319, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.167392, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.076201, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.232961, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.157558, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.330180, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.283642, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.163123, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.331565, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.404167, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.188150, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.441295, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.068600, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.364755, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.212599, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.128207, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.121540, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.024118, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.939308, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.422518, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.381779, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.321666, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.138238, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.135899, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.166023, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.297579, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.133557, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.212286, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.282922, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.026195, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.237881, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.280440, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.126200, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.263944, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.136968, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.371337, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229599, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.242691, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.263285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.274737, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!\n",
    "\n",
    "**Комментарий**: Перед тем как устроить перебор по всей сетке параметров, подберем на глаз: поставим Momentum, увеличим число нейронов в скрытом слое, поставим не такую большую регуляризацию. В случае успеха не придется делать перебор.\n",
    "\n",
    "UPD: Сработало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.303635, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.293074, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.265773, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.208682, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.037252, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 1.885547, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.887529, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.115065, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 1.874202, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.605316, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Loss: 1.537099, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Loss: 1.184568, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 0.842651, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 0.958606, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.295460, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.699491, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.606351, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.008545, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.001062, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.218953, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 300, reg = 1e-5)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1, num_epochs=20, batch_size=10)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.231223, Train accuracy: 0.334889, val accuracy: 0.336000\n",
      "Loss: 2.242964, Train accuracy: 0.435111, val accuracy: 0.452000\n",
      "Loss: 1.741416, Train accuracy: 0.609333, val accuracy: 0.592000\n",
      "Loss: 1.532193, Train accuracy: 0.622000, val accuracy: 0.586000\n",
      "Loss: 1.458880, Train accuracy: 0.641556, val accuracy: 0.608000\n",
      "Loss: 1.512123, Train accuracy: 0.662000, val accuracy: 0.623000\n",
      "Loss: 1.611035, Train accuracy: 0.625222, val accuracy: 0.615000\n",
      "Loss: 1.564311, Train accuracy: 0.630667, val accuracy: 0.589000\n",
      "Loss: 1.360436, Train accuracy: 0.618778, val accuracy: 0.589000\n",
      "Loss: 1.324650, Train accuracy: 0.624333, val accuracy: 0.582000\n",
      "Loss: 1.408848, Train accuracy: 0.636778, val accuracy: 0.595000\n",
      "Loss: 1.657688, Train accuracy: 0.666333, val accuracy: 0.633000\n",
      "Loss: 1.259272, Train accuracy: 0.662222, val accuracy: 0.627000\n",
      "Loss: 1.824181, Train accuracy: 0.659667, val accuracy: 0.612000\n",
      "Loss: 1.327270, Train accuracy: 0.676667, val accuracy: 0.634000\n",
      "Loss: 1.663748, Train accuracy: 0.671667, val accuracy: 0.648000\n",
      "Loss: 2.283421, Train accuracy: 0.196778, val accuracy: 0.206000\n",
      "Loss: 1.760609, Train accuracy: 0.409778, val accuracy: 0.405000\n",
      "Loss: 1.306161, Train accuracy: 0.538000, val accuracy: 0.529000\n",
      "Loss: 1.315899, Train accuracy: 0.592333, val accuracy: 0.582000\n",
      "Loss: 1.219416, Train accuracy: 0.631778, val accuracy: 0.633000\n",
      "Loss: 0.993193, Train accuracy: 0.667556, val accuracy: 0.641000\n",
      "Loss: 1.864158, Train accuracy: 0.682222, val accuracy: 0.650000\n",
      "Loss: 1.133171, Train accuracy: 0.670333, val accuracy: 0.642000\n",
      "Loss: 1.493355, Train accuracy: 0.692889, val accuracy: 0.652000\n",
      "Loss: 1.225825, Train accuracy: 0.721333, val accuracy: 0.676000\n",
      "Loss: 1.105109, Train accuracy: 0.707889, val accuracy: 0.658000\n",
      "Loss: 0.992856, Train accuracy: 0.717111, val accuracy: 0.675000\n",
      "Loss: 1.204162, Train accuracy: 0.719111, val accuracy: 0.663000\n",
      "Loss: 1.144025, Train accuracy: 0.711556, val accuracy: 0.672000\n",
      "Loss: 1.297845, Train accuracy: 0.725778, val accuracy: 0.669000\n",
      "Loss: 1.704538, Train accuracy: 0.737889, val accuracy: 0.681000\n",
      "Loss: 1.922151, Train accuracy: 0.348333, val accuracy: 0.343000\n",
      "Loss: 1.557404, Train accuracy: 0.458444, val accuracy: 0.446000\n",
      "Loss: 1.252670, Train accuracy: 0.587778, val accuracy: 0.586000\n",
      "Loss: 1.617368, Train accuracy: 0.596556, val accuracy: 0.557000\n",
      "Loss: 1.342606, Train accuracy: 0.636222, val accuracy: 0.608000\n",
      "Loss: 1.991553, Train accuracy: 0.618778, val accuracy: 0.576000\n",
      "Loss: 1.371547, Train accuracy: 0.685333, val accuracy: 0.635000\n",
      "Loss: 1.656831, Train accuracy: 0.650333, val accuracy: 0.597000\n",
      "Loss: 1.179999, Train accuracy: 0.654333, val accuracy: 0.621000\n",
      "Loss: 1.730324, Train accuracy: 0.669000, val accuracy: 0.640000\n",
      "Loss: 1.365550, Train accuracy: 0.683778, val accuracy: 0.653000\n",
      "Loss: 1.704351, Train accuracy: 0.684778, val accuracy: 0.644000\n",
      "Loss: 1.605527, Train accuracy: 0.688333, val accuracy: 0.664000\n",
      "Loss: 1.367563, Train accuracy: 0.665667, val accuracy: 0.612000\n",
      "Loss: 1.313000, Train accuracy: 0.688556, val accuracy: 0.632000\n",
      "Loss: 1.315796, Train accuracy: 0.665444, val accuracy: 0.614000\n",
      "Loss: 2.296437, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.664097, Train accuracy: 0.422111, val accuracy: 0.429000\n",
      "Loss: 1.558539, Train accuracy: 0.575111, val accuracy: 0.557000\n",
      "Loss: 1.436170, Train accuracy: 0.634444, val accuracy: 0.627000\n",
      "Loss: 1.731204, Train accuracy: 0.649667, val accuracy: 0.641000\n",
      "Loss: 1.402705, Train accuracy: 0.698556, val accuracy: 0.680000\n",
      "Loss: 0.935433, Train accuracy: 0.678000, val accuracy: 0.657000\n",
      "Loss: 1.127585, Train accuracy: 0.721556, val accuracy: 0.685000\n",
      "Loss: 0.995524, Train accuracy: 0.714889, val accuracy: 0.681000\n",
      "Loss: 0.950983, Train accuracy: 0.697889, val accuracy: 0.672000\n",
      "Loss: 1.198121, Train accuracy: 0.757000, val accuracy: 0.688000\n",
      "Loss: 1.210466, Train accuracy: 0.707778, val accuracy: 0.663000\n",
      "Loss: 1.046510, Train accuracy: 0.746889, val accuracy: 0.698000\n",
      "Loss: 1.568973, Train accuracy: 0.742444, val accuracy: 0.684000\n",
      "Loss: 1.086615, Train accuracy: 0.713444, val accuracy: 0.637000\n",
      "Loss: 1.557350, Train accuracy: 0.751556, val accuracy: 0.688000\n",
      "Loss: 1.832009, Train accuracy: 0.404111, val accuracy: 0.402000\n",
      "Loss: 2.173249, Train accuracy: 0.539111, val accuracy: 0.563000\n",
      "Loss: 1.690513, Train accuracy: 0.568889, val accuracy: 0.533000\n",
      "Loss: 1.151423, Train accuracy: 0.600222, val accuracy: 0.577000\n",
      "Loss: 1.435660, Train accuracy: 0.617222, val accuracy: 0.613000\n",
      "Loss: 1.795149, Train accuracy: 0.650778, val accuracy: 0.608000\n",
      "Loss: 1.641104, Train accuracy: 0.642667, val accuracy: 0.618000\n",
      "Loss: 1.656744, Train accuracy: 0.644222, val accuracy: 0.612000\n",
      "Loss: 1.656683, Train accuracy: 0.641889, val accuracy: 0.626000\n",
      "Loss: 1.376326, Train accuracy: 0.669333, val accuracy: 0.634000\n",
      "Loss: 1.745577, Train accuracy: 0.661444, val accuracy: 0.603000\n",
      "Loss: 1.385157, Train accuracy: 0.669000, val accuracy: 0.614000\n",
      "Loss: 1.590361, Train accuracy: 0.654889, val accuracy: 0.622000\n",
      "Loss: 1.484689, Train accuracy: 0.685444, val accuracy: 0.620000\n",
      "Loss: 1.469148, Train accuracy: 0.639778, val accuracy: 0.584000\n",
      "Loss: 1.452993, Train accuracy: 0.655889, val accuracy: 0.592000\n",
      "Loss: 1.980836, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.665672, Train accuracy: 0.443222, val accuracy: 0.438000\n",
      "Loss: 1.371885, Train accuracy: 0.542111, val accuracy: 0.518000\n",
      "Loss: 1.338698, Train accuracy: 0.646222, val accuracy: 0.645000\n",
      "Loss: 1.179652, Train accuracy: 0.625222, val accuracy: 0.592000\n",
      "Loss: 1.170412, Train accuracy: 0.677000, val accuracy: 0.670000\n",
      "Loss: 1.426265, Train accuracy: 0.690444, val accuracy: 0.652000\n",
      "Loss: 1.383362, Train accuracy: 0.687222, val accuracy: 0.640000\n",
      "Loss: 0.796537, Train accuracy: 0.710778, val accuracy: 0.666000\n",
      "Loss: 1.392880, Train accuracy: 0.710889, val accuracy: 0.674000\n",
      "Loss: 1.321653, Train accuracy: 0.680778, val accuracy: 0.618000\n",
      "Loss: 1.152690, Train accuracy: 0.748111, val accuracy: 0.690000\n",
      "Loss: 1.071124, Train accuracy: 0.767000, val accuracy: 0.699000\n",
      "Loss: 1.076809, Train accuracy: 0.771556, val accuracy: 0.697000\n",
      "Loss: 1.337327, Train accuracy: 0.736000, val accuracy: 0.660000\n",
      "Loss: 1.060399, Train accuracy: 0.762889, val accuracy: 0.692000\n",
      "Loss: 1.699185, Train accuracy: 0.359222, val accuracy: 0.372000\n",
      "Loss: 1.548246, Train accuracy: 0.573111, val accuracy: 0.583000\n",
      "Loss: 1.701252, Train accuracy: 0.598667, val accuracy: 0.578000\n",
      "Loss: 1.215942, Train accuracy: 0.618222, val accuracy: 0.604000\n",
      "Loss: 1.336984, Train accuracy: 0.608778, val accuracy: 0.586000\n",
      "Loss: 1.382726, Train accuracy: 0.632333, val accuracy: 0.622000\n",
      "Loss: 1.172618, Train accuracy: 0.673778, val accuracy: 0.638000\n",
      "Loss: 1.143001, Train accuracy: 0.697667, val accuracy: 0.643000\n",
      "Loss: 1.191780, Train accuracy: 0.688778, val accuracy: 0.621000\n",
      "Loss: 1.160092, Train accuracy: 0.722333, val accuracy: 0.636000\n",
      "Loss: 1.172641, Train accuracy: 0.729667, val accuracy: 0.648000\n",
      "Loss: 1.624410, Train accuracy: 0.729333, val accuracy: 0.654000\n",
      "Loss: 0.736973, Train accuracy: 0.743667, val accuracy: 0.660000\n",
      "Loss: 1.136735, Train accuracy: 0.749222, val accuracy: 0.666000\n",
      "Loss: 1.289311, Train accuracy: 0.755000, val accuracy: 0.663000\n",
      "Loss: 0.757627, Train accuracy: 0.753667, val accuracy: 0.670000\n",
      "Loss: 2.046962, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.990593, Train accuracy: 0.380778, val accuracy: 0.378000\n",
      "Loss: 1.610232, Train accuracy: 0.529444, val accuracy: 0.532000\n",
      "Loss: 1.244238, Train accuracy: 0.619556, val accuracy: 0.613000\n",
      "Loss: 1.233372, Train accuracy: 0.657000, val accuracy: 0.640000\n",
      "Loss: 1.145386, Train accuracy: 0.683333, val accuracy: 0.640000\n",
      "Loss: 0.831342, Train accuracy: 0.687556, val accuracy: 0.629000\n",
      "Loss: 1.805183, Train accuracy: 0.721889, val accuracy: 0.688000\n",
      "Loss: 0.917851, Train accuracy: 0.723667, val accuracy: 0.675000\n",
      "Loss: 1.092379, Train accuracy: 0.732778, val accuracy: 0.673000\n",
      "Loss: 0.564182, Train accuracy: 0.778778, val accuracy: 0.689000\n",
      "Loss: 0.839087, Train accuracy: 0.747889, val accuracy: 0.675000\n",
      "Loss: 0.524013, Train accuracy: 0.761333, val accuracy: 0.704000\n",
      "Loss: 1.078141, Train accuracy: 0.759778, val accuracy: 0.679000\n",
      "Loss: 0.442025, Train accuracy: 0.781889, val accuracy: 0.695000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.636031, Train accuracy: 0.787889, val accuracy: 0.682000\n",
      "Loss: 1.897811, Train accuracy: 0.338778, val accuracy: 0.350000\n",
      "Loss: 1.567589, Train accuracy: 0.585444, val accuracy: 0.571000\n",
      "Loss: 0.926535, Train accuracy: 0.620556, val accuracy: 0.614000\n",
      "Loss: 1.220348, Train accuracy: 0.591000, val accuracy: 0.552000\n",
      "Loss: 1.280089, Train accuracy: 0.657667, val accuracy: 0.625000\n",
      "Loss: 1.040229, Train accuracy: 0.672667, val accuracy: 0.636000\n",
      "Loss: 1.293408, Train accuracy: 0.688222, val accuracy: 0.635000\n",
      "Loss: 1.270849, Train accuracy: 0.726889, val accuracy: 0.672000\n",
      "Loss: 1.062738, Train accuracy: 0.716556, val accuracy: 0.636000\n",
      "Loss: 0.886852, Train accuracy: 0.739889, val accuracy: 0.671000\n",
      "Loss: 0.536044, Train accuracy: 0.704222, val accuracy: 0.631000\n",
      "Loss: 0.743393, Train accuracy: 0.722111, val accuracy: 0.659000\n",
      "Loss: 0.880421, Train accuracy: 0.736889, val accuracy: 0.648000\n",
      "Loss: 1.609742, Train accuracy: 0.723667, val accuracy: 0.638000\n",
      "Loss: 1.305231, Train accuracy: 0.752111, val accuracy: 0.643000\n",
      "Loss: 0.969906, Train accuracy: 0.758333, val accuracy: 0.634000\n",
      "Loss: 2.201302, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.850740, Train accuracy: 0.425556, val accuracy: 0.431000\n",
      "Loss: 1.296964, Train accuracy: 0.555333, val accuracy: 0.543000\n",
      "Loss: 1.229860, Train accuracy: 0.615111, val accuracy: 0.615000\n",
      "Loss: 0.937830, Train accuracy: 0.677111, val accuracy: 0.643000\n",
      "Loss: 1.100051, Train accuracy: 0.689000, val accuracy: 0.657000\n",
      "Loss: 1.467758, Train accuracy: 0.672333, val accuracy: 0.650000\n",
      "Loss: 0.691331, Train accuracy: 0.714667, val accuracy: 0.660000\n",
      "Loss: 0.685740, Train accuracy: 0.730111, val accuracy: 0.664000\n",
      "Loss: 0.596655, Train accuracy: 0.739667, val accuracy: 0.673000\n",
      "Loss: 0.624415, Train accuracy: 0.788889, val accuracy: 0.716000\n",
      "Loss: 0.583265, Train accuracy: 0.773000, val accuracy: 0.682000\n",
      "Loss: 0.915691, Train accuracy: 0.792778, val accuracy: 0.694000\n",
      "Loss: 0.915316, Train accuracy: 0.818000, val accuracy: 0.713000\n",
      "Loss: 0.612492, Train accuracy: 0.801222, val accuracy: 0.691000\n",
      "Loss: 1.036738, Train accuracy: 0.796000, val accuracy: 0.702000\n",
      "Loss: 1.694902, Train accuracy: 0.343889, val accuracy: 0.349000\n",
      "Loss: 1.358491, Train accuracy: 0.578778, val accuracy: 0.578000\n",
      "Loss: 1.458192, Train accuracy: 0.628667, val accuracy: 0.616000\n",
      "Loss: 1.574846, Train accuracy: 0.589889, val accuracy: 0.566000\n",
      "Loss: 1.257553, Train accuracy: 0.635889, val accuracy: 0.608000\n",
      "Loss: 1.219898, Train accuracy: 0.674000, val accuracy: 0.635000\n",
      "Loss: 1.222497, Train accuracy: 0.702556, val accuracy: 0.639000\n",
      "Loss: 1.221695, Train accuracy: 0.685000, val accuracy: 0.631000\n",
      "Loss: 2.016240, Train accuracy: 0.714222, val accuracy: 0.636000\n",
      "Loss: 0.614362, Train accuracy: 0.759333, val accuracy: 0.686000\n",
      "Loss: 0.940530, Train accuracy: 0.747667, val accuracy: 0.687000\n",
      "Loss: 0.736463, Train accuracy: 0.739000, val accuracy: 0.667000\n",
      "Loss: 1.575207, Train accuracy: 0.766889, val accuracy: 0.673000\n",
      "Loss: 1.016397, Train accuracy: 0.739333, val accuracy: 0.646000\n",
      "Loss: 0.743590, Train accuracy: 0.766222, val accuracy: 0.686000\n",
      "Loss: 0.987756, Train accuracy: 0.774778, val accuracy: 0.665000\n",
      "Loss: 2.334008, Train accuracy: 0.240222, val accuracy: 0.242000\n",
      "Loss: 1.594532, Train accuracy: 0.428222, val accuracy: 0.410000\n",
      "Loss: 1.272354, Train accuracy: 0.569889, val accuracy: 0.555000\n",
      "Loss: 1.218466, Train accuracy: 0.647778, val accuracy: 0.598000\n",
      "Loss: 0.879753, Train accuracy: 0.682778, val accuracy: 0.648000\n",
      "Loss: 1.170467, Train accuracy: 0.710111, val accuracy: 0.668000\n",
      "Loss: 1.234797, Train accuracy: 0.678556, val accuracy: 0.644000\n",
      "Loss: 0.954545, Train accuracy: 0.751000, val accuracy: 0.679000\n",
      "Loss: 0.750597, Train accuracy: 0.757000, val accuracy: 0.675000\n",
      "Loss: 0.582269, Train accuracy: 0.762889, val accuracy: 0.678000\n",
      "Loss: 1.052509, Train accuracy: 0.774333, val accuracy: 0.690000\n",
      "Loss: 0.704638, Train accuracy: 0.805889, val accuracy: 0.719000\n",
      "Loss: 1.064078, Train accuracy: 0.809556, val accuracy: 0.712000\n",
      "Loss: 1.590260, Train accuracy: 0.808667, val accuracy: 0.714000\n",
      "Loss: 0.510700, Train accuracy: 0.817556, val accuracy: 0.729000\n",
      "Loss: 0.352842, Train accuracy: 0.806556, val accuracy: 0.702000\n",
      "Loss: 2.250804, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.206662, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179783, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.197709, Train accuracy: 0.243667, val accuracy: 0.240000\n",
      "Loss: 1.904460, Train accuracy: 0.276889, val accuracy: 0.284000\n",
      "Loss: 1.665545, Train accuracy: 0.379556, val accuracy: 0.382000\n",
      "Loss: 1.475194, Train accuracy: 0.448778, val accuracy: 0.447000\n",
      "Loss: 1.735474, Train accuracy: 0.501556, val accuracy: 0.489000\n",
      "Loss: 1.534676, Train accuracy: 0.553000, val accuracy: 0.556000\n",
      "Loss: 1.503627, Train accuracy: 0.601889, val accuracy: 0.590000\n",
      "Loss: 1.363507, Train accuracy: 0.615889, val accuracy: 0.618000\n",
      "Loss: 1.489341, Train accuracy: 0.644778, val accuracy: 0.625000\n",
      "Loss: 1.313010, Train accuracy: 0.657667, val accuracy: 0.646000\n",
      "Loss: 1.221449, Train accuracy: 0.658333, val accuracy: 0.653000\n",
      "Loss: 1.024846, Train accuracy: 0.702000, val accuracy: 0.688000\n",
      "Loss: 1.175960, Train accuracy: 0.690000, val accuracy: 0.659000\n",
      "Loss: 2.257133, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236554, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233849, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258963, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213942, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.426916, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.146945, Train accuracy: 0.212778, val accuracy: 0.220000\n",
      "Loss: 2.147654, Train accuracy: 0.254222, val accuracy: 0.256000\n",
      "Loss: 2.249473, Train accuracy: 0.275556, val accuracy: 0.279000\n",
      "Loss: 2.003087, Train accuracy: 0.291222, val accuracy: 0.292000\n",
      "Loss: 1.687425, Train accuracy: 0.337444, val accuracy: 0.341000\n",
      "Loss: 1.897194, Train accuracy: 0.389889, val accuracy: 0.381000\n",
      "Loss: 1.578410, Train accuracy: 0.421889, val accuracy: 0.416000\n",
      "Loss: 1.476914, Train accuracy: 0.455889, val accuracy: 0.437000\n",
      "Loss: 1.757992, Train accuracy: 0.495000, val accuracy: 0.492000\n",
      "Loss: 1.616416, Train accuracy: 0.515778, val accuracy: 0.501000\n",
      "Loss: 2.201980, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203694, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179481, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.974707, Train accuracy: 0.260556, val accuracy: 0.261000\n",
      "Loss: 1.933018, Train accuracy: 0.292889, val accuracy: 0.294000\n",
      "Loss: 1.794871, Train accuracy: 0.396889, val accuracy: 0.381000\n",
      "Loss: 1.715766, Train accuracy: 0.435444, val accuracy: 0.434000\n",
      "Loss: 1.505211, Train accuracy: 0.524889, val accuracy: 0.523000\n",
      "Loss: 1.630813, Train accuracy: 0.583556, val accuracy: 0.572000\n",
      "Loss: 1.229226, Train accuracy: 0.619444, val accuracy: 0.594000\n",
      "Loss: 1.231340, Train accuracy: 0.634000, val accuracy: 0.619000\n",
      "Loss: 1.208743, Train accuracy: 0.653333, val accuracy: 0.640000\n",
      "Loss: 1.478872, Train accuracy: 0.680778, val accuracy: 0.670000\n",
      "Loss: 1.155015, Train accuracy: 0.703556, val accuracy: 0.684000\n",
      "Loss: 1.081832, Train accuracy: 0.708778, val accuracy: 0.692000\n",
      "Loss: 1.150487, Train accuracy: 0.722556, val accuracy: 0.698000\n",
      "Loss: 2.222381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.200185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170118, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258399, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311373, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179386, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.154034, Train accuracy: 0.229111, val accuracy: 0.237000\n",
      "Loss: 2.023945, Train accuracy: 0.268889, val accuracy: 0.269000\n",
      "Loss: 1.848982, Train accuracy: 0.279556, val accuracy: 0.281000\n",
      "Loss: 2.077729, Train accuracy: 0.304778, val accuracy: 0.309000\n",
      "Loss: 1.701369, Train accuracy: 0.361333, val accuracy: 0.358000\n",
      "Loss: 1.659200, Train accuracy: 0.404444, val accuracy: 0.396000\n",
      "Loss: 1.727298, Train accuracy: 0.443889, val accuracy: 0.437000\n",
      "Loss: 1.601718, Train accuracy: 0.481556, val accuracy: 0.475000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.603230, Train accuracy: 0.510556, val accuracy: 0.512000\n",
      "Loss: 1.530712, Train accuracy: 0.546222, val accuracy: 0.546000\n",
      "Loss: 2.268336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238269, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.195728, Train accuracy: 0.204667, val accuracy: 0.218000\n",
      "Loss: 2.073342, Train accuracy: 0.274556, val accuracy: 0.280000\n",
      "Loss: 1.836626, Train accuracy: 0.347000, val accuracy: 0.352000\n",
      "Loss: 1.823415, Train accuracy: 0.437111, val accuracy: 0.429000\n",
      "Loss: 1.508246, Train accuracy: 0.482222, val accuracy: 0.487000\n",
      "Loss: 1.198392, Train accuracy: 0.566778, val accuracy: 0.558000\n",
      "Loss: 1.529996, Train accuracy: 0.605222, val accuracy: 0.599000\n",
      "Loss: 1.391205, Train accuracy: 0.645556, val accuracy: 0.628000\n",
      "Loss: 1.170167, Train accuracy: 0.669222, val accuracy: 0.663000\n",
      "Loss: 1.327962, Train accuracy: 0.685556, val accuracy: 0.673000\n",
      "Loss: 1.161697, Train accuracy: 0.702889, val accuracy: 0.684000\n",
      "Loss: 1.012636, Train accuracy: 0.713000, val accuracy: 0.690000\n",
      "Loss: 1.352057, Train accuracy: 0.716000, val accuracy: 0.687000\n",
      "Loss: 0.960522, Train accuracy: 0.730222, val accuracy: 0.711000\n",
      "Loss: 2.269456, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.363432, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258204, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.109031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225565, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187745, Train accuracy: 0.214111, val accuracy: 0.220000\n",
      "Loss: 2.047137, Train accuracy: 0.248667, val accuracy: 0.252000\n",
      "Loss: 1.982779, Train accuracy: 0.276444, val accuracy: 0.276000\n",
      "Loss: 2.037214, Train accuracy: 0.308333, val accuracy: 0.318000\n",
      "Loss: 2.101009, Train accuracy: 0.360444, val accuracy: 0.364000\n",
      "Loss: 1.732271, Train accuracy: 0.406667, val accuracy: 0.394000\n",
      "Loss: 1.853857, Train accuracy: 0.452000, val accuracy: 0.443000\n",
      "Loss: 1.633260, Train accuracy: 0.482222, val accuracy: 0.469000\n",
      "Loss: 1.590316, Train accuracy: 0.521667, val accuracy: 0.512000\n",
      "Loss: 1.497183, Train accuracy: 0.557667, val accuracy: 0.554000\n",
      "Loss: 1.303262, Train accuracy: 0.589000, val accuracy: 0.567000\n",
      "Loss: 2.289981, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237997, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292662, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.182723, Train accuracy: 0.253333, val accuracy: 0.256000\n",
      "Loss: 1.877402, Train accuracy: 0.295111, val accuracy: 0.298000\n",
      "Loss: 1.852309, Train accuracy: 0.394333, val accuracy: 0.382000\n",
      "Loss: 1.754416, Train accuracy: 0.462111, val accuracy: 0.463000\n",
      "Loss: 1.723648, Train accuracy: 0.527444, val accuracy: 0.523000\n",
      "Loss: 1.109559, Train accuracy: 0.584667, val accuracy: 0.573000\n",
      "Loss: 1.179559, Train accuracy: 0.618778, val accuracy: 0.604000\n",
      "Loss: 1.131507, Train accuracy: 0.641889, val accuracy: 0.632000\n",
      "Loss: 1.031206, Train accuracy: 0.654889, val accuracy: 0.642000\n",
      "Loss: 0.997610, Train accuracy: 0.686778, val accuracy: 0.659000\n",
      "Loss: 0.895829, Train accuracy: 0.701222, val accuracy: 0.678000\n",
      "Loss: 0.907106, Train accuracy: 0.705778, val accuracy: 0.686000\n",
      "Loss: 0.933622, Train accuracy: 0.723333, val accuracy: 0.690000\n",
      "Loss: 2.289840, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279692, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.185780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223254, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.151472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.135714, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202175, Train accuracy: 0.216556, val accuracy: 0.222000\n",
      "Loss: 2.147958, Train accuracy: 0.262556, val accuracy: 0.258000\n",
      "Loss: 1.954104, Train accuracy: 0.275000, val accuracy: 0.275000\n",
      "Loss: 2.056237, Train accuracy: 0.298000, val accuracy: 0.305000\n",
      "Loss: 1.789824, Train accuracy: 0.355778, val accuracy: 0.354000\n",
      "Loss: 1.715691, Train accuracy: 0.399000, val accuracy: 0.395000\n",
      "Loss: 1.725871, Train accuracy: 0.442000, val accuracy: 0.442000\n",
      "Loss: 1.753031, Train accuracy: 0.475000, val accuracy: 0.463000\n",
      "Loss: 1.605542, Train accuracy: 0.518889, val accuracy: 0.508000\n",
      "Loss: 1.271716, Train accuracy: 0.551556, val accuracy: 0.543000\n",
      "Loss: 2.239425, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.121674, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.058855, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.135678, Train accuracy: 0.266556, val accuracy: 0.264000\n",
      "Loss: 1.684070, Train accuracy: 0.330111, val accuracy: 0.339000\n",
      "Loss: 1.756106, Train accuracy: 0.414667, val accuracy: 0.417000\n",
      "Loss: 1.350325, Train accuracy: 0.493889, val accuracy: 0.504000\n",
      "Loss: 1.336326, Train accuracy: 0.556889, val accuracy: 0.561000\n",
      "Loss: 0.977574, Train accuracy: 0.599000, val accuracy: 0.580000\n",
      "Loss: 1.265377, Train accuracy: 0.630667, val accuracy: 0.628000\n",
      "Loss: 0.955603, Train accuracy: 0.660444, val accuracy: 0.662000\n",
      "Loss: 1.251498, Train accuracy: 0.688444, val accuracy: 0.677000\n",
      "Loss: 0.789828, Train accuracy: 0.695889, val accuracy: 0.669000\n",
      "Loss: 0.939623, Train accuracy: 0.715333, val accuracy: 0.680000\n",
      "Loss: 0.848039, Train accuracy: 0.714444, val accuracy: 0.697000\n",
      "Loss: 0.959931, Train accuracy: 0.743778, val accuracy: 0.708000\n",
      "Loss: 2.237848, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221048, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187391, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198037, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.127053, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142352, Train accuracy: 0.199000, val accuracy: 0.209000\n",
      "Loss: 2.040921, Train accuracy: 0.234667, val accuracy: 0.240000\n",
      "Loss: 2.126854, Train accuracy: 0.265444, val accuracy: 0.263000\n",
      "Loss: 1.995297, Train accuracy: 0.278000, val accuracy: 0.278000\n",
      "Loss: 2.022068, Train accuracy: 0.305778, val accuracy: 0.321000\n",
      "Loss: 1.676617, Train accuracy: 0.354222, val accuracy: 0.355000\n",
      "Loss: 1.763107, Train accuracy: 0.401222, val accuracy: 0.398000\n",
      "Loss: 1.338911, Train accuracy: 0.423222, val accuracy: 0.424000\n",
      "Loss: 1.470573, Train accuracy: 0.461667, val accuracy: 0.460000\n",
      "Loss: 1.721440, Train accuracy: 0.501111, val accuracy: 0.497000\n",
      "Loss: 1.505906, Train accuracy: 0.541222, val accuracy: 0.529000\n",
      "Loss: 2.220864, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.169987, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.102340, Train accuracy: 0.215556, val accuracy: 0.221000\n",
      "Loss: 2.003781, Train accuracy: 0.277889, val accuracy: 0.285000\n",
      "Loss: 1.866454, Train accuracy: 0.367333, val accuracy: 0.356000\n",
      "Loss: 1.666138, Train accuracy: 0.468111, val accuracy: 0.454000\n",
      "Loss: 1.511352, Train accuracy: 0.536000, val accuracy: 0.524000\n",
      "Loss: 1.213135, Train accuracy: 0.578778, val accuracy: 0.566000\n",
      "Loss: 1.449247, Train accuracy: 0.602333, val accuracy: 0.585000\n",
      "Loss: 1.025749, Train accuracy: 0.650778, val accuracy: 0.634000\n",
      "Loss: 1.103906, Train accuracy: 0.679778, val accuracy: 0.665000\n",
      "Loss: 1.270968, Train accuracy: 0.695222, val accuracy: 0.673000\n",
      "Loss: 0.804730, Train accuracy: 0.710889, val accuracy: 0.683000\n",
      "Loss: 0.731304, Train accuracy: 0.711111, val accuracy: 0.685000\n",
      "Loss: 1.223538, Train accuracy: 0.737444, val accuracy: 0.709000\n",
      "Loss: 1.192599, Train accuracy: 0.745444, val accuracy: 0.699000\n",
      "Loss: 2.269379, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.168206, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240937, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.148207, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.125856, Train accuracy: 0.209778, val accuracy: 0.219000\n",
      "Loss: 2.149331, Train accuracy: 0.264556, val accuracy: 0.260000\n",
      "Loss: 1.958270, Train accuracy: 0.280667, val accuracy: 0.278000\n",
      "Loss: 1.960481, Train accuracy: 0.310111, val accuracy: 0.311000\n",
      "Loss: 1.788533, Train accuracy: 0.375889, val accuracy: 0.383000\n",
      "Loss: 1.911900, Train accuracy: 0.413556, val accuracy: 0.401000\n",
      "Loss: 1.844649, Train accuracy: 0.451222, val accuracy: 0.447000\n",
      "Loss: 1.505619, Train accuracy: 0.501778, val accuracy: 0.486000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.306304, Train accuracy: 0.531556, val accuracy: 0.529000\n",
      "Loss: 1.323790, Train accuracy: 0.571556, val accuracy: 0.550000\n",
      "Loss: 1.270325, Train accuracy: 0.597778, val accuracy: 0.579000\n",
      "best validation accuracy achieved: 0.711000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "# Best parameters for now are (0.78, 50, 25, 200, 0.9, 0.8, 0.001, 0.1)\n",
    "# best_parameters = (val_history[len(val_history)-1], batch, epoch, laysize, decay, moment, reg, rate)\n",
    "\n",
    "learning_rates = [1e-1, 1e-2]\n",
    "reg_strength = [1e-3, 1e-5]\n",
    "hidden_layer_sizes = [64, 128, 256]\n",
    "batch_size = [64, 128]\n",
    "num_epochs = 16\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "for lr in learning_rates:\n",
    "    for rs in reg_strength:\n",
    "        for ls in hidden_layer_sizes:\n",
    "            for bs in batch_size:\n",
    "                model = TwoLayerNet(n_input=train_X.shape[1], n_output=10, hidden_layer_size=ls, reg=rs)\n",
    "                trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=lr, num_epochs=num_epochs, batch_size=bs)\n",
    "                temp_loss_history, temp_train_history, temp_val_history = trainer.fit()\n",
    "                \n",
    "                if temp_val_history[-1] > best_val_accuracy:\n",
    "                    best_classifier = model\n",
    "                    best_val_accuracy = temp_val_history[-1]\n",
    "                    loss_history = temp_loss_history.copy()\n",
    "                    train_history = temp_train_history.copy()\n",
    "                    val_history = temp_val_history.copy()\n",
    "    \n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb2a33df518>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.648000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
